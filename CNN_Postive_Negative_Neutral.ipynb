{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e383abd7",
   "metadata": {},
   "source": [
    "# CNN for positive, negative and neutral classification\n",
    "***\n",
    "QuaternairCombinedPN is the **RAVDESS**, **CREMA-D**, **TESS** and **SAVEE** dataset combined<br>\n",
    "**RAVDESS** and **CREMA-D** has equal _male_ and _female_ sample<br>\n",
    "**TESS** has only _female_ samples<br>\n",
    "**SAVEE** has only _male_ samples<br>\n",
    "***\n",
    "\n",
    "Dataloaders that are used<br>\n",
    "**Epochs: 5**<br>\n",
    "_Following results are with a unbalanced dataset_\n",
    "* **NormalCrema** - _Anger, Disgust, Fear, Happy, Neutral, & Sad_ \n",
    "  * Train Acc: 49.46%\n",
    "  * Validate Acc: 47.98%\n",
    "  * Precision: 49.46%\n",
    "* **BinairCrema** - _Positive & Negative_\n",
    "  * Train Acc: 68.26%\n",
    "  * Validate Acc: 72.92%\n",
    "  * Precision: 72.92%\n",
    "* **MaleSplitCremaBinair** - _Male samples Positive, Negative & Neutral_\n",
    "  * Train Acc: 59.16%\n",
    "  * Validate Acc: 59.46%\n",
    "  * Precision: 59.46%\n",
    "* **FemaleSplitCremaBinair** - _Female samples Positive, Negative & Neutral_\n",
    "  * Train Acc: 62.01%\n",
    "  * Validate Acc: 66.31%\n",
    "  * Precision: 66.31%\n",
    "* **QuaternairCombinedPN** - _Positive, Negative & Neutral_\n",
    "  * Train Acc: 74.51%\n",
    "  * Validate Acc: 74.23%\n",
    "  * Precision: 74.51%\n",
    "* **QuaternairCombinedMaleSplitPN** - _Male samples Positive, Negative & Neutral_\n",
    "  * Train Acc: ?%\n",
    "  * Validate Acc: ?%\n",
    "  * Precision: ?%\n",
    "* **QuaternairCombinedFemaleSplitPN** - _Female samples Positive, Negative & Neutral_\n",
    "  * Train Acc: ?%\n",
    "  * Validate Acc: ?%\n",
    "  * Precision: ?%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dc08443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326902b5",
   "metadata": {},
   "source": [
    "# Fetch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63d91569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run /data/emo/notebooks/source/pipeline/generator.ipynb\n",
    "# train_ds, valid_ds = Generator.generate(MaleSplitCremaBinair, Spectrogram).to_dataset()\n",
    "\n",
    "# train_loader = utils.DataLoader(train_ds, batch_size=batch_size, shuffle=True , num_workers=4)\n",
    "# valid_loader = utils.DataLoader(valid_ds, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# print(\"Using\", len(train_ds), \"files for training.\")\n",
    "# print(\"Using\", len(valid_ds), \"files for validation.\")\n",
    "\n",
    "# for i in range(4):\n",
    "#     print(train_ds[i][0].shape)\n",
    "#     plt.imshow(train_ds[i][0].permute(1, 2, 0))\n",
    "#     plt.axis('off'); \n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e3a74c",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddbdab35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using gpu 3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchmetrics\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as fn\n",
    "# from torchsummary import summary\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "class Convolutional(pl.LightningModule):\n",
    "    def __init__(self, cnn_output:int):\n",
    "        super().__init__()\n",
    "        self.cnn_output = cnn_output\n",
    "        self.configure_metrics()\n",
    "        self.loss_func = nn.CrossEntropyLoss()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.pool2 = nn.MaxPool2d(4, 4)\n",
    "        self.pool3 = nn.MaxPool2d(4, 4)\n",
    "        self.fc1 = nn.Linear(64*3*7, 64)\n",
    "        self.fc2 = nn.Linear(64, cnn_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(fn.relu(self.conv1(x)))\n",
    "        x = self.pool2(fn.relu(self.conv2(x)))\n",
    "        x = self.pool3(fn.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 64*3*7) # Flatten layer\n",
    "        x = fn.relu(self.fc1(x))\n",
    "        x = fn.log_softmax(self.fc2(x), dim=1)\n",
    "        return x\n",
    "    \n",
    "    def configure_metrics(self):\n",
    "        self.train_acc = torchmetrics.Accuracy()\n",
    "        self.valid_acc = torchmetrics.Accuracy()\n",
    "        self.valid_precision = torchmetrics.Precision(num_classes=self.cnn_output)\n",
    "        self.valid_recall = torchmetrics.Recall(num_classes=self.cnn_output)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=0.001, weight_decay=0.01)\n",
    "#         optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        return optimizer\n",
    "    \n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, y = val_batch\n",
    "        output = self(x)\n",
    "        loss = self.loss_func(output, y)\n",
    "        self.valid_precision(output, y)\n",
    "        self.valid_recall(output, y)\n",
    "        self.valid_acc(output, y)\n",
    "        self.log(\"precision\", self.valid_precision, on_step=False, on_epoch=True, logger=True)\n",
    "        self.log(\"recall\", self.valid_recall, on_step=False, on_epoch=True, logger=True)\n",
    "        self.log('val_acc', self.valid_acc, on_step=False, on_epoch=True, logger=True)\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True, logger=True)\n",
    "        \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x, y = train_batch\n",
    "        output = self(x)\n",
    "        loss = self.loss_func(output, y)\n",
    "        self.train_acc(output, y)\n",
    "        self.log('train_acc', self.train_acc, on_step=False, on_epoch=True, logger=True)\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def on_train_start(self):\n",
    "        self.log(\"hp/metric_1\", 0.001)\n",
    "        self.log(\"hp/metric_2\", 32)\n",
    "\n",
    "# network = Convolutional()\n",
    "# summary(network, (3, 128, 256))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c076f26",
   "metadata": {},
   "source": [
    "## Callback function\n",
    "Should only contain logging and visualization logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8382c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(monitor=\"val_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3c57def",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import Callback\n",
    "\n",
    "class ConvolutionalCallback(Callback):\n",
    "#     def __init__(self):\n",
    "#         self.conv_layers = []\n",
    "    \n",
    "#     def on_train_start(self, trainer, pl_module):\n",
    "#         self.writer(\"hp/metric_1\", 0.001)\n",
    "#         self.writer(\"hp/metric_2\", 32)\n",
    "    \n",
    "    def on_fit_start(self, trainer, pl_module):\n",
    "        \"\"\"Callback function that gets executed before the fit starts\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        trainer : pl.Trainer\n",
    "            The trainer of the CNN module (pl_module)\n",
    "        pl_module : pl.LightningModule\n",
    "            The model we want to use to retrieve information\n",
    "        \"\"\"    \n",
    "        self.writer = pl_module.logger.experiment\n",
    "\n",
    "        # Connect the hooks to the CNN\n",
    "        pl_module.fc1.register_forward_hook(self.activation_hook)\n",
    "        pl_module.fc2.register_forward_hook(self.activation_hook)\n",
    "\n",
    "    def activation_hook(self, inst, inp, out):\n",
    "        \"\"\"Run activation hook\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        inst : torch.nn.Module\n",
    "            The layer we want to attach the hook to.\n",
    "        inp : torch.Tensor\n",
    "            The input to the `forward` method.\n",
    "        out : torch.Tensor\n",
    "            The output of the `forward` method.\n",
    "        \"\"\"\n",
    "        # Create histogram of layer weights\n",
    "        self.writer.add_histogram(repr(inst), out)\n",
    "\n",
    "        # Create a grid with filterd images\n",
    "        img_grid = torchvision.utils.make_grid(inp[0])\n",
    "        self.writer.add_image('Forward Input images', img_grid)\n",
    "\n",
    "        # Create a grid with filterd images\n",
    "        img_grid = torchvision.utils.make_grid(out)\n",
    "        self.writer.add_image('Forward Output images', img_grid)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae39fcb4",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d26c07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run /data/emo/notebooks/source/pipeline/generator.ipynb\n",
    "\n",
    "batch_size = 32\n",
    "n_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9738576b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_training(dataloader, cnn_output:int):\n",
    "    print(\"Get dataset\")\n",
    "#    train_ds, valid_ds = Generator.generate(dataloader, LogSpectrogram).to_dataset()\n",
    "    train_ds, valid_ds = Generator.generate(dataloader, Spectrogram).to_dataset()\n",
    "\n",
    "    train_loader = utils.DataLoader(train_ds, batch_size=batch_size, shuffle=True , num_workers=4)\n",
    "    valid_loader = utils.DataLoader(valid_ds, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    print(\"Using\", len(train_ds), \"files for training.\")\n",
    "    print(\"Using\", len(valid_ds), \"files for validation.\")\n",
    "\n",
    "    # ssh -L 6006:127.0.0.1:6006 18082920@datascience.hhs.nl\n",
    "    # tensorboard --logdir ./tb_logs\n",
    "    logger = pl.loggers.TensorBoardLogger('tb_logs', name='convolutional_pn')\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=n_epochs, \n",
    "        weights_summary=None, \n",
    "        logger=logger, \n",
    "        callbacks=[ConvolutionalCallback(), checkpoint_callback]\n",
    "    )\n",
    "    \n",
    "    print(\"Start start training\")\n",
    "    network = Convolutional(cnn_output)\n",
    "\n",
    "    trainer.fit(network, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211bfc2c",
   "metadata": {},
   "source": [
    "## NormalCrema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfc81e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute_training(NormalCrema, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47680353",
   "metadata": {},
   "source": [
    "## BinairCrema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11744297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute_training(BinairCrema, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65af7c6f",
   "metadata": {},
   "source": [
    "## MaleSplitCremaBinair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37c46fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute_training(MaleSplitCremaBinair, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d07c145",
   "metadata": {},
   "source": [
    "## FemaleSplitCremaBinair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "101721a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute_training(FemaleSplitCremaBinair, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cb00b8",
   "metadata": {},
   "source": [
    "## QuaternairCombinedPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "930f9c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/jupyterhub/anaconda/lib/python3.9/site-packages/matplotlib/axes/_axes.py:7723: RuntimeWarning: divide by zero encountered in log10\n",
      "  Z = 10. * np.log10(spec)\n",
      "/opt/jupyterhub/anaconda/lib/python3.9/site-packages/matplotlib/axes/_axes.py:7723: RuntimeWarning: divide by zero encountered in log10\n",
      "  Z = 10. * np.log10(spec)\n",
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 8145 files for training.\n",
      "Using 2037 files for validation.\n",
      "Start start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/jupyterhub/anaconda/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1303: UserWarning: GPU available but not used. Set the gpus flag in your trainer `Trainer(gpus=1)` or script `--gpus=1`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4ee9c20da954925ba3d0cafec911a04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "execute_training(QuaternairCombinedPN, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8048f6e",
   "metadata": {},
   "source": [
    "## QuaternairCombined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4afbfb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/jupyterhub/anaconda/lib/python3.9/site-packages/matplotlib/axes/_axes.py:7723: RuntimeWarning: divide by zero encountered in log10\n",
      "  Z = 10. * np.log10(spec)\n",
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 7544 files for training.\n",
      "Using 1886 files for validation.\n",
      "Start start training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2084318412e74173aea84152743d8128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "execute_training(QuaternairCombined, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf172d3",
   "metadata": {},
   "source": [
    "## MaleSplitRAVDESSBinair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76e19d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#execute_training(MaleBinairRavdess, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b421f181",
   "metadata": {},
   "source": [
    "## FemaleSplitRAVDESSBinair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "979eafff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#execute_training(FemaleBinairRavdess, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664d9c41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
