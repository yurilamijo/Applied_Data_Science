# Portfolio Applied Data Science
Name: Yuri Lamijo<br/>
Studentnumber: 18050697<br/>
Course: Minor Applied Data Science

# Project Emo
_Project Emo is in staat gesteld door de heer Hani Al-Ers die werkzaam is bij een Lectoraat van De Haagse Hogeschool._

Project Teddy is in deze minor opgesplits in drie verschillende projecten. Deze projecten zijn project Nurish, Dialog en Emo. Beide project hebben te maken met het classificeren van kenmerken in audio.
<br/><br/>

## Task Definition
Het doel van project Emo is het herkennen van emoties uit spraak audio van ouderen met dementie. Zorgverleners kunnen hiermee de quality of Life van een ouder in kaart brengen. Verder kunnen ze sneller actie ondernemen wanneer de quality of life van een ouder verslechterd.

Gebaseerd op het probleemstelling, project domein, feedback van de docenten en de product owner is de volgende hoofdvraag opgestelt.
> Which machine learning models achieve the highest precision classifying emotions, using (four) datasets containing audio with labeled vocal emotional expressions recorded in a professional recording studio, in order to recognize emotions within household environments?

Vanuit deze hoofdvraag zijn de volgende sub onderzoekvragen opgesteld.
> Which machine learning algorithms are available in literature to classify emotions from audio? 

> How can precision in machine learning algorithms be improved for the TESS, SAVEE, RAVDESS and CREMA-D datasets?

> Can the known methods of classifying be reproduced with the same precision/recall on the available dataset?

<br/><br/>

# Planning
Het project team was bij de kick off van de minor geadviseerd om de werkzaamheden uit te voeren en te planning in de Agile techniek. Hierom hebben wij unaniem gekozen om SCRUM toe te passen. Vier van de project leden waaronder ik waren al bekend SCUM. Waardoor wij de andere 2 project leden konden ondersteunen met het SCRUM process. Verder had het team besloten om een vaste SCRUM master rol toe tewijzen. Deze rol had ik vervuld.

Sprints tot sprint 3 duurde een week. Dit liep echter niet zoals verwacht. De user stories die uitgevoerd werden, moesten vaak mee genomen worden omdat deze nog niet af was of omdat deze net te groot was. Hierom hadden wij er voor gekozen om sprints te houden van 2 weken. Aan het eind van iedere sprint werd er met het team een retrospective gehouden die daarna gevolgd werd door een sprint planning voor de volgende sprint.
<br/><br/>


<details>
<summary>Project plan - Miro</summary>
In sprint 3, hadden wij een Miro timeline board gemaakt. Daarin werd de werkzaamheden (user stories) en potentiele werkzaamheden zichtbaar gemaakt. Hierdoor konden wij een globale planning maken voor de gehele minor en het project. Dit timeline board heeft naar mijn mening veel geholden bij het beslissen en prioriseren van welke user stories bepaalde sprints uitgevoerd moeten worden.

zichtbaar gemaakt welke werkzaamheden in bepaalde sprint uitgevoerd werden.

![Miro timeline planning](https://gcdn.pbrd.co/images/id0k4ReDnCfR.jpg?o=1)
_Figuur 1 - Miro timeline planning_
</details>
<details>
<summary>Github - SCRUM</summary>
As a group we decided to use the project board of Girhub as our SCRUM board. The User Stories and Epics where applied through the creation of issues. The SCRUM board was divided into 4 sections: <b>To do</b>, <b>In progress</b>, <b>Waiting for feedback</b> and <b>Done</b>

I was responsible for the creation of the user stories.At the end of each sprint we held a sprint planning. In this planning we looked at our Miror board and disscused which task should be executed. 

![Sprint 8 backlog](https://gcdn.pbrd.co/images/zaFEIkf5La2M.png?o=1)
_Figuur 2 - Sprint 8 backlog_

</details>
<details><summary>Daily stand-up/ Retrospective</summary>
<b>Daily standup</b><br />
In de daily standup, vertelde we wat voor werkzaamheden uitvoerd waren, knelpunten die voorkwamen en welke werkzaamheden we van plan zijn uit te voeren. Hierdoor wist het team exact wie welke werkzaamheden uitvoerde of mogelijk hulp nodig heeft.
<br /><br />

<b>Retrospective </b><br />

Voor iedere retrospective is er een afbeelding geexpoteerd, zodat alle geschreven tickets en actiepunten terug gevonden kon worden. De afbeeldingen kunnen terug gevonden worden in de wiki pagina [Retrospective](https://github.com/koendebruijn/Emotions/wiki/Retrospective) in de [Emotions GitHub repositorie](https://github.com/koendebruijn/Emotions).  
</details>
<br /><br />

# Communication
<details>
<summary>Discord</summary>
Het team had aan het begin van het project afgesproken om all communicatie over het project via Discord te doen. In Discord hadden we hiervoor een aparte discord server gemaakt voor alle project emo leden. Hierin werden relevanten documenten, websites en video tutorials met elkaar gedeeld. Verder werden hier ook de daily stand-ups, retrospectives, sprint planningen en andere meetings gehouden.
<br /><br />
Omdat het Smart Teddy Bear project uit drie verschillende projecten bestaat en ook te maken had met het clasificeren van audio. Hadden wij het initiatief genomen om een discord server op te zetten met daarin alle project groepen gerelateerd op het Smart Teddy Bear project. Hierin kon iedereen relevante research papers en resulten met elkaar delen.
<br /><br />
</details>
<details>
<summary>Google Drive</summary>
Om tegelijk met het team te werken aan documenten werd er gebruik gemaakt van Google Drive. Hierin maakten wij de presentaties voor de interne, externe en product owner meetings. 
<br /><br />
</details>
<br />

## Presentations
Tijdens het project werden er presentaties gegeven in de interne, externe en product owner meetings. Deze presentaties werden samen met het team ingedeeld en opgezet. De Interne presentaties werden begeleid door Jaap en ondersteund door de rest van het team.
Voor de externe presentaties hadden we besloten om deze te houden met maximaal 4 verschillende team leden. De taak verdeling voor deze presentaties werd tijdens het opzet van een presentatie uitgevoerd.
De product owner presentaties werd door Berno begeleid met ondersteuning van het team om vragen te kunnen beantwoorden.

Mijn bijdragen bij het maken presentatie was het vullen van de presentatie met resultaten en de machine learning modellen en CNN.
Verder controleerde ik de presentaties of feedback punten van vorig presentaties verbeterd waren in het nieuwe presentatie.
<br />
Presentaties heb ik zelf niet individuele uitgevoerd. Deze werden altijd in team verband uitgevoerd. Ik heb echter zelf alleen specifieke delen van presentaties gepresenteerd. De presentaties waarin ik onderdelen heb gepresenteerd heb ik onderin in een lijst benoemd.

The presentations with the product owner were held by Breno
* Internal presentations were I take part of
    * [Internal Presentation -]()
    * [Internal Presentation -]()
    * [Internal Presentation -]()
* External presentations were I take part of
    * [External Presentation 1]()
    * [External Presentation 3]()

<br /><br />

# Research Paper
Als team hadden we besloten dat iedereen aan de research paper kon gaan werken.

Voor de research paper is gebruik gemaakt van de [{...} template](). Die gebruik maakt van de IEEE standaard.

Het initieel opzet van de research paper werdt gedaan door Breno, Zahir en ik. Wij begonnen eerst met het opzetten van het structuur van de paper. Daarna begonnen we eerst met de Introduction en Background hoofstukken. Nadat alle expirimenten van de CNN uitgevoerd waren en er definitieve resultaten waren sloten Jaap, Koen en Julian aan bij het schrijven van de paper.
<br />
Nadat alle hoodstukken gevuld en af waren, liepen we met ze alle gezamelijk alinea voor alinea na om de inhoud, spelling, grammatica en samenhang te controleren. Hierdoor kon iedereen zijn mening en feedback geven. Waardoor we naar mijn mening een redelijke research paper hebben kunnen opzetten.


Voor de research paper heb ik de volgende delen met feedback en samenwerking van het team geschreven:
* Introductie
* Methodology
    * Architecture
* Results
<br /><br />

# Reflection and Evaluation
<details>
<summary>Persoonlijke leerdoelen evaluatie</summary>
</details>
<details>
<summary>Persoonlijke project bijdragen evaluatie</summary>
</details>
<details>
<summary>Groeps evaluatie</summary>
</details>

<br />

# Datacamp
Tijdens de minor heb ik de DataCamp cursussen die aangeboden werden gevolgd. Persoonlijk vond ik deze cursussen zeer leerzaam op het gebied van Data Science. Ik hiervoor geen idee hoe Data Science praktisch inelkaar zat en deze cursussen gaven hier een aardig goed beeld. Onderin in dit hoofdstuk heb ik een afebeelding toegevoegd met daarin de DataCamp cursussen die ik heb afgerond.

![Uitgevoerde DataCamp cursussen](https://gcdn.pbrd.co/images/E7pkfRINI68j.png?o=1)
_Figuur 4 - Uitgevoerde DataCamp cursussen_


<br /><br />


# Domain knowledge
Voordat er machine learning models en neural networks ontwikkeld konden worden moest er eerst kennis opgedaan worden over het domein. Hiervoor heb ik literatuur onderzoek naar relevante onderzoeken en projecten die emoties classificeren uit audio. Verder kregen we ook documenten van onze product owner, zodat we ons konden inlezen op het domein en het Smart Teddy Bear project.
<br /><br />

## Introduction of the subject field
De Smart Teddy is een therapeutisch partner die ouderen observeert doormiddel van sensoren in de Smart Teddy. De teddy bezit op het moment een aantal basis functionaliteiten zoals het observeren op het hoeveelheid aan plezier op een dag heeft en of ouderen genoeg laang genoeg slapen. Deze infromatie wordt dan in beeld gebracht in een dashboard voor verzorgers. Hiermee wordt er een schatting gemaakt over de Quality of Life van de ouder. Verzorgers kunnen met deze informatie sneller handelen en mogelijk de Quality of Life van een ouder verbeteren.

![Smart Teddy dashboard](https://bigdata-thuas.eu/wp-content/uploads/2017/10/Screenshot-2021-04-10-at-23.32.41-300x161@2x.png)
_Figuur 2 - Smart Teddy dashboard_

<br />
De product owner wilt voor de volgende prototype een aantal functionaliteiten toevoegen aan de teddy. Een van die functionaliteiten is het herkennen van emoties via spraak audio. Met behulp van deze functionaliteiten kan er in het dashboard aangegeven worden hoe vaak bepaalde emoties zijn geuit op een dag. Verzorgers die niet ter plekken zijn kunnen hierdoor een beeld de situatie krijgen zonder er fysiek bij te zijn. 
<br /><br />

## Literature Research
In dit hoofdstuk wordt er in kaart gebracht wat de resultaten waren van literatuur onderzoek.

<details>
<summary>Speech Emotion Detection using IoT based Deep Learning for Health Care
</summary>

Links: [IEEE](https://ieeexplore.ieee.org/abstract/document/9005638/authors#authors), [PDF](https://www.researchgate.net/profile/Sayed-Shah-6/publication/337992475_Speech_Emotion_Detection_using_IoT_based_Deep_Learning_for_Health_Care/links/5df968d392851c8364854a33/Speech-Emotion-Detection-using-IoT-based-Deep-Learning-for-Health-Care.pdf)

Deze research paper stelde een CNN als oplossing voor het classificeren van emoties. Voor het trainen van hun model maakten ze gebruik van de RAVDESS dataset. Verder beschreef deze paper duidelijk welke stappen er waren ondernomen en hoe iedere stap invloed had op de resultaten. Daarom adviseerde ik het team om ook deze paper door te nemen en het te gebruiken als baseline voor onze model en paper.

<b>Data Augmentation</b>
Deze paper maakte gebruik van 3 vormen van data augmentatie. Deze waren: Time Stretching, Pitch Shifiting en Dynamic Range Compression. Na het uitvoeren van data augemntatie verbeterde zij de resultaten van de CNN

<b>Results</b>
Hun uiteindelijke model resulteerde in 95% voor mannen en 97% voor vrouwen. Zij hebben kunnen aantonen dat het mogelijk is om emoties te kunnen herkennen uit spraak audio met hoge accuractie.

<b>Conclusion</b>


De researcher van de paper hebben hoge resultaten behaald, maar er kan echter niet gesproken worden van een model dat zulke resulatten zal krijgen bij realistisch auido.

Het RAVDESS dataset wordt namelijk door profesionele acteuren en actresses in gesproken in een profesionele studio. Verder bestaat de ingesproken audio uit 2 verschillende zinnen. 

---

</details>
<details>
<summary>Audio feature extraction research
</summary>

[Source 1](https://medium.com/analytics-vidhya/understanding-the-mel-spectrogram-fca2afa2ce53),
[Source 2](https://towardsdatascience.com/how-i-understood-what-features-to-consider-while-training-audio-files-eedfb6e9002b)

</details>
<br /><br />

## Explanation of Terminology, jargon and definitions
In dit hoofdstuk worden de gevonden en gebruikten terminologies, jargon en definities van het project uitgelegd.

* Ambient noise -
* Chromagram -
* Convolutional Neural Network -
* Mel-Frequency Cepstral Coefficients (MFCC's) -
* Multilayer perceptron -
* Spectrogram -
* Threshold -
* Transfer Learning -
* Waveform -
* Quality of Life
* Zero-crossing rate -


<br />

# TODO
## Executed user stories
Give list of executed user stories
## Data preparation
Tell about the handeling of data preparation

## Data collection
Tell about data collection, which datasets where used and why

## Created models
Tell about the models I have created and explain why

### Multi Layer Perceptron (MLP)
Creation of MLP model for classification of emotions

### Convolutional Neural Network (CNN)
Creation of CNN for classification of objects 