{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ff86232",
   "metadata": {},
   "source": [
    "# Multi-layer Perceptron Classifier\n",
    "\n",
    "Source: https://towardsdatascience.com/building-a-speech-emotion-recognizer-using-python-4c1c7c89d713\n",
    "\n",
    "This model optimizes the log-loss function using LBFGS or stochastic gradient descent.\n",
    "\n",
    "Uses the notebook \"Preprocessing\" to preprocess the audio and store the results in a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2057888",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, glob, pickle, json \n",
    "import time\n",
    "\n",
    "from sklearn.metrics import recall_score, precision_score, classification_report, plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from ipynb.fs.full.base_model import BaseModel\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv  \n",
    "from sklearn.model_selection import HalvingGridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a9fbf9",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# BASELINE DATASETS\n",
    "CREMA_D_JSON_FILE_NAME = '../preprocced data/data/baseline/crema-d_preprocessed_data.json'\n",
    "RAVDESS_JSON_FILE_NAME = '../preprocced data/data/baseline/ravdess_preprocessed_data_V0.1.json'\n",
    "\n",
    "# AUGMENTED\n",
    "AUGMENTED_CREMA_D_JSON_FILE_NAME = '../preprocced data/data/augmented_crema-d_preprocessed_data.json'\n",
    "AUGMENTED_RAVDESS_JSON_FILE_NAME = '../preprocced data/data/augmented_ravdess_preprocessed_data.json'\n",
    "\n",
    "# Male data\n",
    "MALE_CREMA_D_JSON_FILE_NAME = '../preprocced data/data/baseline/crema-d_male_preprocessed_data.json'\n",
    "MALE_RAVDESS_JSON_FILE_NAME = '../preprocced data/data/baseline/ravdess_male_preprocessed_data_V0.1.json'\n",
    "\n",
    "#Female\n",
    "FEMALE_CREMA_D_JSON_FILE_NAME = '../preprocced data/data/baseline/crema-d_female_preprocessed_data.json'\n",
    "FEMALE_RAVDESS_JSON_FILE_NAME = '../preprocced data/data/baseline/ravdess_female_preprocessed_data_V0.1.json'\n",
    "\n",
    "MODEL_FILENAME = 'MLP_Model.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47fa731",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(BaseModel):    \n",
    "    \"\"\"\n",
    "        RECALL - GRIDSEARCH RESULTS\n",
    "    \"\"\"\n",
    "#     model = MLPClassifier(hidden_layer_sizes=(200),\n",
    "#                           activation='logistic',\n",
    "#                           learning_rate='adaptive',\n",
    "#                           max_iter=400,\n",
    "#                           solver='sgd',\n",
    "#                          )\n",
    "    \n",
    "    \"\"\"\n",
    "        ACCURACY - GRIDSEARCH RESULT\n",
    "    \"\"\"\n",
    "    model = MLPClassifier(hidden_layer_sizes=(100,),\n",
    "                          activation='logistic',\n",
    "                          learning_rate='adaptive',\n",
    "                          max_iter=400,\n",
    "                          solver='adam',\n",
    "                         )\n",
    "\n",
    "\n",
    "#     model = MLPClassifier(hidden_layer_sizes=(300,),\n",
    "#                           activation='logistic',\n",
    "#                           learning_rate='constant',\n",
    "#                           max_iter=10,\n",
    "#                           alpha=0.003,\n",
    "#                           solver='adam',\n",
    "#                           verbose=True\n",
    "#                          )\n",
    "    \n",
    "    @classmethod\n",
    "    def train(cls, dataset_name):\n",
    "        train = super().read_dataset(dataset_type='train', dataset_name=dataset_name)\n",
    "        test = super().read_dataset(dataset_type='test', dataset_name=dataset_name)\n",
    "\n",
    "        x_train = np.array(train['features'])\n",
    "        y_train = np.array(train['emotions'])\n",
    "        x_test = np.array(test['features'])\n",
    "        y_test = np.array(test['emotions'])\n",
    "\n",
    "        cls.model.fit(X_train, y_train)\n",
    "\n",
    "        print(f\"\\nORIGINAL MODEl: {dataset_name}\")\n",
    "        super().model_accuracy(cls.model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "        # Augmented data training\n",
    "        X_train = train_dataset['Augmented']['X']\n",
    "        y_train = train_dataset['Augmented']['y']\n",
    "        X_test = test_dataset['Augmented']['X']\n",
    "        y_test = test_dataset['Augmented']['y']\n",
    "\n",
    "        cls.model.fit(X_train, y_train)\n",
    "\n",
    "        print(f\"\\nAUGMENTED MODEl: {dataset_name}\")\n",
    "        super().model_accuracy(cls.model, X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    @classmethod\n",
    "    def grid_search(cls, dataset_name, is_augmented=False):\n",
    "        # train dataset\n",
    "        train_dataset = super().read_dataset(dataset_type='train', dataset_name=dataset_name)\n",
    "\n",
    "        X_train, y_train = [], []\n",
    "        \n",
    "        if is_augmented:\n",
    "            X_train = train_dataset['Augmented']['X']\n",
    "            y_train = train_dataset['Augmented']['y']\n",
    "        else:\n",
    "            X_train = train_dataset['OriginalData']['X']\n",
    "            y_train = train_dataset['OriginalData']['y']\n",
    "        \n",
    "        # GridSearchCV Train accuracy\n",
    "        param_grid = [\n",
    "            {\n",
    "                'activation' : ['logistic', 'tanh', 'relu'],\n",
    "                'solver' : ['sgd', 'adam'],\n",
    "                'hidden_layer_sizes': [\n",
    "                     (100,), (200,), (300,)\n",
    "                 ],\n",
    "                'alpha': [0.0001, 0.05],\n",
    "                'learning_rate': ['constant', 'adaptive'],\n",
    "                'max_iter': [100],\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        clf = GridSearchCV(model, param_grid, cv=5, scoring=scoring, n_jobs=5) \n",
    "        \n",
    "        start_time = time.perf_counter()\n",
    "        clf.fit(X_train, y_train)\n",
    "        end_time = time.perf_counter()\n",
    "        \n",
    "        print(f\"Duration fitting: {end_time - start_time:04f}\")\n",
    "        \n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print(clf.best_params_)\n",
    "        print(clf.best_estimator_)\n",
    "        print(clf.best_score_)\n",
    "        \n",
    "        return clf\n",
    "    \n",
    "    @classmethod\n",
    "    def train_default(cls, path, title):\n",
    "        \"\"\"\n",
    "            Training method that uses the normal dataset\n",
    "        \"\"\"\n",
    "        with open(path) as file:\n",
    "            data = json.load(file)\n",
    "\n",
    "        x = np.array(data['features'])\n",
    "        y = np.array(data['emotions'])\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "        cls.model.fit(X_train, y_train)\n",
    "        \n",
    "        print(f\"\\nDEFAULT MODEl: {title}\")\n",
    "        super().model_accuracy(cls.model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739f8171",
   "metadata": {},
   "source": [
    "## RAVDESS Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa62ac78",
   "metadata": {},
   "source": [
    "### Accuracy with train, test and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e6cf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP.train(\"ravdess\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090145d1",
   "metadata": {},
   "source": [
    "## CREMA-D Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e052a9",
   "metadata": {},
   "source": [
    "### Accuracy with train, test and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c803b1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP.train(\"crema-d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e718f49",
   "metadata": {},
   "source": [
    "# Female and Male accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c2c568",
   "metadata": {},
   "source": [
    "This chapter shows the accuracy of the original, male and female data of the RAVDESS and CREMA-D dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c7bf16",
   "metadata": {},
   "source": [
    "## RAVDESS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c197495",
   "metadata": {},
   "source": [
    "RAVDESS - ORIGINAL DATA: The following code shows the accuracy of the default RAVDESS dataset without augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432d23d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP.train_default(RAVDESS_JSON_FILE_NAME, \"RAVDESS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c3e1c7",
   "metadata": {},
   "source": [
    "RAVDESS - MALE DATA: The following code shows the accuracy of the male RAVDESS dataset without augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed8b516",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP.train_default(MALE_RAVDESS_JSON_FILE_NAME, \"RAVDESS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7d9da8",
   "metadata": {},
   "source": [
    "RAVDESS - FEMALE DATA: The following code shows the accuracy of the female RAVDESS dataset without augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7553f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP.train_default(FEMALE_RAVDESS_JSON_FILE_NAME, \"RAVDESS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb90d2b0",
   "metadata": {},
   "source": [
    "## CREMA-D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3334b0",
   "metadata": {},
   "source": [
    "CREMA-D - ORIGINAL DATA: The following code shows the accuracy of the default CREMA-Ddataset without augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32be7689",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP.train_default(CREMA_D_JSON_FILE_NAME, \"CREMA-D\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f06fe5d",
   "metadata": {},
   "source": [
    "CREMA-D - MALE DATA: The following code shows the accuracy of the male RAVDESS dataset without augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55debae",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP.train_default(MALE_CREMA_D_JSON_FILE_NAME, \"CREMA-D\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9269cc",
   "metadata": {},
   "source": [
    "CREMA-D - FEMALE DATA: The following code shows the accuracy of the female RAVDESS dataset without augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fef115",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP.train_default(FEMALE_CREMA_D_JSON_FILE_NAME, \"CREMA-D\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90bbe32",
   "metadata": {},
   "source": [
    "# Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb8fc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAVDESS - Not augmented\n",
    "gridsearch_model = MLP.grid_search('ravdess', is_augmented=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963c22ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAVDESS - augmented\n",
    "gridsearch_model = MLP.grid_search('ravdess', is_augmented=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5dbadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREMA-D - Not augmented\n",
    "gridsearch_model = MLP.grid_search('crema-d', is_augmented=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801018f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREMA-D - augmented\n",
    "gridsearch_model = MLP.grid_search('crema-d', is_augmented=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f57b8d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
