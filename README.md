# Portfolio Applied Data Science
Name: Yuri Lamijo<br/>
Studentnumber: 18050697<br/>
Course: Minor Applied Data Science

# Project Emo
_Project Emo is in staat gesteld door de heer Hani Al-Ers die werkzaam is bij een Lectoraat van De Haagse Hogeschool._

Project Teddy is in deze minor opgesplits in drie verschillende projecten. Deze projecten zijn project Nurish, Dialog en Emo. Beide project hebben te maken met het classificeren van kenmerken in audio.
<br/><br/>

## Task Definition
Het doel van project Emo is het herkennen van emoties uit spraak audio van ouderen met dementie. Zorgverleners kunnen hiermee de quality of Life van een ouder in kaart brengen. Verder kunnen ze sneller actie ondernemen wanneer de quality of life van een ouder verslechterd.

Gebaseerd op het probleemstelling, project domein, feedback van de docenten en de product owner is de volgende hoofdvraag opgestelt.
> Which machine learning models achieve the highest precision classifying emotions, using (four) datasets containing audio with labeled vocal emotional expressions recorded in a professional recording studio, in order to recognize emotions within household environments?

Vanuit deze hoofdvraag zijn de volgende sub onderzoekvragen opgesteld.
> Which machine learning algorithms are available in literature to classify emotions from audio? 

> How can precision in machine learning algorithms be improved for the TESS, SAVEE, RAVDESS and CREMA-D datasets?

> Can the known methods of classifying be reproduced with the same precision/recall on the available dataset?

<br/><br/>

# Planning
Het project team was bij de kick off van de minor geadviseerd om de werkzaamheden uit te voeren en te planning in de Agile techniek. Hierom hebben wij unaniem gekozen om SCRUM toe te passen. Vier van de project leden waaronder ik waren al bekend SCUM. Waardoor wij de andere 2 project leden konden ondersteunen met het SCRUM process. Verder had het team besloten om een vaste SCRUM master rol toe tewijzen. Deze rol had ik vervuld.

Sprints tot sprint 3 duurde een week. Dit liep echter niet zoals verwacht. De user stories die uitgevoerd werden, moesten vaak mee genomen worden omdat deze nog niet af was of omdat deze net te groot was. Hierom hadden wij er voor gekozen om sprints te houden van 2 weken. Aan het eind van iedere sprint werd er met het team een retrospective gehouden die daarna gevolgd werd door een sprint planning voor de volgende sprint.
<br/><br/>


<details>
<summary>Project plan - Miro</summary>
In sprint 3, hadden wij een Miro timeline board gemaakt. Daarin werd de werkzaamheden (user stories) en potentiele werkzaamheden zichtbaar gemaakt. Hierdoor konden wij een globale planning maken voor de gehele minor en het project. Dit timeline board heeft naar mijn mening veel geholden bij het beslissen en prioriseren van welke user stories bepaalde sprints uitgevoerd moeten worden.

zichtbaar gemaakt welke werkzaamheden in bepaalde sprint uitgevoerd werden.

![Miro timeline planning](https://gcdn.pbrd.co/images/id0k4ReDnCfR.jpg?o=1)
_Figuur 1 - Miro timeline planning_
</details>
<details>
<summary>Github - SCRUM</summary>
As a group we decided to use the project board of Girhub as our SCRUM board. The User Stories and Epics where applied through the creation of issues. The SCRUM board was divided into 4 sections: <b>To do</b>, <b>In progress</b>, <b>Waiting for feedback</b> and <b>Done</b>

I was responsible for the creation of the user stories.At the end of each sprint we held a sprint planning. In this planning we looked at our Miror board and disscused which task should be executed. 

![Sprint 8 backlog](https://gcdn.pbrd.co/images/zaFEIkf5La2M.png?o=1)
_Figuur 2 - Sprint 8 backlog_

</details>
<details><summary>Daily stand-up/ Retrospective</summary>
<b>Daily standup</b><br />
In de daily standup, vertelde we wat voor werkzaamheden uitvoerd waren, knelpunten die voorkwamen en welke werkzaamheden we van plan zijn uit te voeren. Hierdoor wist het team exact wie welke werkzaamheden uitvoerde of mogelijk hulp nodig heeft.
<br /><br />

<b>Retrospective </b><br />

Voor iedere retrospective is er een afbeelding geexpoteerd, zodat alle geschreven tickets en actiepunten terug gevonden kon worden. De afbeeldingen kunnen terug gevonden worden in de wiki pagina [Retrospective](https://github.com/koendebruijn/Emotions/wiki/Retrospective) in de [Emotions GitHub repositorie](https://github.com/koendebruijn/Emotions).  
</details>
<br /><br />

# Communication
<details>
<summary>Discord</summary>
Het team had aan het begin van het project afgesproken om all communicatie over het project via Discord te doen. In Discord hadden we hiervoor een aparte discord server gemaakt voor alle project emo leden. Hierin werden relevanten documenten, websites en video tutorials met elkaar gedeeld. Verder werden hier ook de daily stand-ups, retrospectives, sprint planningen en andere meetings gehouden.
<br /><br />
Omdat het Smart Teddy Bear project uit drie verschillende projecten bestaat en ook te maken had met het clasificeren van audio. Hadden wij het initiatief genomen om een discord server op te zetten met daarin alle project groepen gerelateerd op het Smart Teddy Bear project. Hierin kon iedereen relevante research papers en resulten met elkaar delen.
<br /><br />
</details>
<details>
<summary>Google Drive</summary>
Om tegelijk met het team te werken aan documenten werd er gebruik gemaakt van Google Drive. Hierin maakten wij de presentaties voor de interne, externe en product owner meetings. 
<br /><br />
</details>
<br />

## Presentations
Tijdens het project werden er presentaties gegeven in de interne, externe en product owner meetings. Deze presentaties werden samen met het team ingedeeld en opgezet. De Interne presentaties werden begeleid door Jaap en ondersteund door de rest van het team.
Voor de externe presentaties hadden we besloten om deze te houden met maximaal 4 verschillende team leden. De taak verdeling voor deze presentaties werd tijdens het opzet van een presentatie uitgevoerd.
De product owner presentaties werd door Berno begeleid met ondersteuning van het team om vragen te kunnen beantwoorden.

Mijn bijdragen bij het maken presentatie was het vullen van de presentatie met resultaten en de machine learning modellen en CNN.
Verder controleerde ik de presentaties of feedback punten van vorig presentaties verbeterd waren in het nieuwe presentatie.
<br />
Presentaties heb ik zelf niet individuele uitgevoerd. Deze werden altijd in team verband uitgevoerd. Ik heb echter zelf alleen specifieke delen van presentaties gepresenteerd. De presentaties waarin ik onderdelen heb gepresenteerd heb ik onderin in een lijst benoemd.

The presentations with the product owner were held by Breno
* Internal presentations were I take part of
    * [Internal Presentation -]()
    * [Internal Presentation -]()
    * [Internal Presentation -]()
* External presentations were I take part of
    * [External Presentation 1]()
    * [External Presentation 3]()

<br /><br />

# Research Paper
Als team hadden we besloten dat iedereen aan de research paper kon gaan werken.

Voor de research paper is gebruik gemaakt van de [{...} template](). Die gebruik maakt van de IEEE standaard.

Het initieel opzet van de research paper werdt gedaan door Breno, Zahir en ik. Wij begonnen eerst met het opzetten van het structuur van de paper. Daarna begonnen we eerst met de Introduction en Background hoofstukken. Nadat alle expirimenten van de CNN uitgevoerd waren en er definitieve resultaten waren sloten Jaap, Koen en Julian aan bij het schrijven van de paper.
<br />
Nadat alle hoodstukken gevuld en af waren, liepen we met ze alle gezamelijk alinea voor alinea na om de inhoud, spelling, grammatica en samenhang te controleren. Hierdoor kon iedereen zijn mening en feedback geven. Waardoor we naar mijn mening een redelijke research paper hebben kunnen opzetten.


Voor de research paper heb ik de volgende delen met feedback en samenwerking van het team geschreven:
* Introductie
* Methodology
    * Architecture
* Results
<br /><br />

# Reflection and Evaluation
<details>
<summary>Persoonlijke leerdoelen evaluatie</summary>
</details>
<details>
<summary>Persoonlijke project bijdragen evaluatie</summary>
</details>
<details>
<summary>Groeps evaluatie</summary>
</details>

<br />

# Predictive Analysis
Voor het project heb ik een Multi Layer Perceptron (MLP) model van start tot eind gemaakt. Daarnaast heb ik ook gewerkt aan de Convolutional Neural Network (CNN) die wij als team hebben opgeleverd.
<br /><br />

## Multi Layer Perceptron (MLP)

[MLP model notebook]()

### Selecting a Model


source: https://towardsdatascience.com/building-a-speech-emotion-recognizer-using-python-4c1c7c89d713


### Configruing a Model

### Evaluting a Model

### Visualizing the outcome of a model

<br /><br />

## Convolutional Neural Network (CNN)
### Selecting a Model

### Configruing a Model

### Evaluting a Model

### Visualizing the outcome of a model

<br /><br />


# Datacamp
Tijdens de minor heb ik de DataCamp cursussen die aangeboden werden gevolgd. Persoonlijk vond ik deze cursussen zeer leerzaam op het gebied van Data Science. Ik hiervoor geen idee hoe Data Science praktisch inelkaar zat en deze cursussen gaven hier een aardig goed beeld. Onderin in dit hoofdstuk heb ik een afebeelding toegevoegd met daarin de DataCamp cursussen die ik heb afgerond.

![Uitgevoerde DataCamp cursussen](https://gcdn.pbrd.co/images/E7pkfRINI68j.png?o=1)
_Figuur 4 - Uitgevoerde DataCamp cursussen_


<br /><br />

# TODO
## Executed user stories
Give list of executed user stories


# Domain knowledge
## Literature Research

<details>
<summary>Speech Emotion Detection using IoT based Deep Learning for Health Care
</summary>

Links: [IEEE](https://ieeexplore.ieee.org/abstract/document/9005638/authors#authors), [PDF](https://www.researchgate.net/profile/Sayed-Shah-6/publication/337992475_Speech_Emotion_Detection_using_IoT_based_Deep_Learning_for_Health_Care/links/5df968d392851c8364854a33/Speech-Emotion-Detection-using-IoT-based-Deep-Learning-for-Health-Care.pdf)

</details>

## Data preparation
Tell about the handeling of data preparation

## Data collection
Tell about data collection, which datasets where used and why


