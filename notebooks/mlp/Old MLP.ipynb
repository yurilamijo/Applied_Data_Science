{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ff86232",
   "metadata": {},
   "source": [
    "# Multi-layer Perceptron Classifier\n",
    "\n",
    "Source: https://towardsdatascience.com/building-a-speech-emotion-recognizer-using-python-4c1c7c89d713\n",
    "\n",
    "This model optimizes the log-loss function using LBFGS or stochastic gradient descent.\n",
    "\n",
    "Uses the notebook \"Preprocessing\" to preprocess the audio and store the results in a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2057888",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, glob, pickle, json \n",
    "\n",
    "from sklearn.metrics import recall_score, precision_score, classification_report, confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import joblib\n",
    "\n",
    "from ipynb.fs.full.basemodel import BaseModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32aee96",
   "metadata": {},
   "source": [
    "# Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0047b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(BaseModel):    \n",
    "    \"\"\"\n",
    "        RECALL - GRIDSEARCH RESULTS\n",
    "    \"\"\"\n",
    "    model = MLPClassifier(hidden_layer_sizes=(200, 300,),\n",
    "                          activation='logistic',\n",
    "                          learning_rate='adaptive',\n",
    "                          max_iter=400,\n",
    "                          solver='sgd',\n",
    "                         )\n",
    "    \n",
    "    \"\"\"\n",
    "        ACCURACY - GRIDSEARCH RESULT\n",
    "    \"\"\"\n",
    "#     model = MLPClassifier(hidden_layer_sizes=(100,),\n",
    "#                           activation='logistic',\n",
    "#                           learning_rate='adaptive',\n",
    "#                           max_iter=400,\n",
    "#                           solver='adam',\n",
    "#                          )\n",
    "\n",
    "    @classmethod\n",
    "    def train(cls, dataset_name):\n",
    "        \"\"\"\n",
    "            Training method that uses the splitted dataset (train, test and validate)\n",
    "        \"\"\"\n",
    "        # train dataset\n",
    "        train_dataset = super().read_dataset(dataset_type='train', dataset_name=dataset_name)\n",
    "        \n",
    "        # test dataset\n",
    "        test_dataset = super().read_dataset(dataset_type='test', dataset_name=dataset_name)\n",
    "        \n",
    "        # Original data training\n",
    "        X_train = train_dataset['OriginalData']['X']\n",
    "        y_train = train_dataset['OriginalData']['y']\n",
    "        X_test = test_dataset['OriginalData']['X']\n",
    "        y_test = test_dataset['OriginalData']['y']\n",
    "\n",
    "        cls.model.fit(X_train, y_train)\n",
    "\n",
    "        print(f\"\\nORIGINAL MODEl: {dataset_name}\")\n",
    "        super().model_accuracy(cls.model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "        # Augmented data training\n",
    "        X_train = train_dataset['Augmented']['X']\n",
    "        y_train = train_dataset['Augmented']['y']\n",
    "        X_test = test_dataset['Augmented']['X']\n",
    "        y_test = test_dataset['Augmented']['y']\n",
    "\n",
    "        cls.model.fit(X_train, y_train)\n",
    "\n",
    "        print(f\"\\nAUGMENTED MODEl: {dataset_name}\")\n",
    "        super().model_accuracy(cls.model, X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    @classmethod\n",
    "    def grid_search(cls, dataset_name, is_augmented=False):\n",
    "        # train dataset\n",
    "        train_dataset = super().read_dataset(dataset_type='train', dataset_name=dataset_name)\n",
    "    \n",
    "        X_train, y_train = [], []\n",
    "        \n",
    "        if is_augmented:\n",
    "            X_train = train_dataset['OriginalData']['X']\n",
    "            y_train = train_dataset['OriginalData']['y']\n",
    "        else:\n",
    "            X_train = train_dataset['Augmented']['X']\n",
    "            y_train = train_dataset['Augmented']['y']\n",
    "        \n",
    "        # GridSearchCV Train accuracy\n",
    "        param_grid = [\n",
    "            {\n",
    "                'activation' : ['logistic', 'tanh', 'relu'],\n",
    "                'solver' : ['sgd', 'adam'],\n",
    "                'hidden_layer_sizes': [\n",
    "                     (100,), (200,), (300,)\n",
    "                 ],\n",
    "                'learning_rate': ['adaptive'],\n",
    "                'max_iter': [400, 500, 600, 700],\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        clf = GridSearchCV(MLPClassifier(), param_grid, cv=3, scoring='recall')\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print(clf.best_params_)\n",
    "        print(clf.best_estimator_)\n",
    "        \n",
    "        return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f67872",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP.train(\"ravdess\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a1150a",
   "metadata": {},
   "source": [
    "## GridSearch CV\n",
    "\n",
    "### Use only for testing new models! This takes A LOT of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a3940b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: remove 'lbfgs' and 'identity'\n",
    "param_grid = [\n",
    "        {\n",
    "            'activation' : ['logistic', 'tanh', 'relu'],\n",
    "            'solver' : ['sgd', 'adam'],\n",
    "            'hidden_layer_sizes': [\n",
    "                 (200,)\n",
    "             ],\n",
    "            'learning_rate': ['adaptive'],\n",
    "            'max_iter': [400, 500, 600],\n",
    "#             'warm_start': [True, False]\n",
    "        }\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237f9570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- In Testing ---\n",
    "clf = GridSearchCV(MLPClassifier(), param_grid, cv=3, scoring='accuracy')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(clf.best_params_)\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff58162",
   "metadata": {},
   "source": [
    "### Accuracy of GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97321a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV Train accuracy\n",
    "y_pred = clf.best_estimator_.predict(X_train)\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "print(\"Train accuracy is: {}\".format(accuracy))\n",
    "\n",
    "# GridSearchCV Test accuracy\n",
    "y_pred = clf.best_estimator_.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test accuracy is: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cd67a0",
   "metadata": {},
   "source": [
    "# _Optional_ Store model thourgh Joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40426c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store model\n",
    "joblib.dump(model, MODEL_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f915e226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "joblib_model = joblib.load(MODEL_FILENAME)\n",
    "\n",
    "# Train accuracy\n",
    "y_pred = joblib_model.predict(X_train)\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "print(\"Train accuracy is: {}\".format(accuracy))\n",
    "\n",
    "# Test accuracy\n",
    "y_pred = joblib_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test accuracy is: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77362e46",
   "metadata": {},
   "source": [
    "## Old Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab31e623",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "kf = KFold(n_splits=n_fold, shuffle=True)\n",
    "acc_test_score = []\n",
    "acc_train_score = []\n",
    "\n",
    "for train_index, test_index in kf.split(x):\n",
    "    X_train , X_test = x[train_index,:], x[test_index,:]\n",
    "    y_train , y_test = y[train_index] , y[test_index]\n",
    "     \n",
    "    model.fit(X_train,y_train)\n",
    "    pred_test_values = model.predict(X_test)    \n",
    "    pred_train_values = model.predict(X_train)\n",
    "\n",
    "    # Test values\n",
    "    acc_test = accuracy_score(pred_test_values , y_test)\n",
    "    acc_test_score.append(acc_test)\n",
    "    \n",
    "    # Train values\n",
    "    acc_train = accuracy_score(pred_train_values , y_train)\n",
    "    acc_train_score.append(acc_train)\n",
    "     \n",
    "avg_test_acc_score = sum(acc_test_score)/n_fold\n",
    "avg_train_acc_score = sum(acc_train_score)/n_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef1326d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train accuracy of each fold - {}'.format(acc_train_score))\n",
    "print('Avg train accuracy : {}'.format(avg_train_acc_score))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print('Test accuracy of each fold - {}'.format(acc_test_score))\n",
    "print('Avg test accuracy : {}'.format(avg_test_acc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b74483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(train, test):\n",
    "    # create train accuracy sublpot\n",
    "    plt.plot(train, label=\"train accuracy\")\n",
    "    plt.plot(test, label=\"test accuracy\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.xlabel(\"Amount of times\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.title(\"Accuracy\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f46286",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy(acc_train_score, acc_test_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
